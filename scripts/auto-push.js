const { exec } = require('child_process');
const chokidar = require('chokidar');
const path = require('path');
const os = require('os');
const fs = require('fs');

// Configuration
const WATCH_PATHS = [
  'app/**/*',
  'components/**/*',
  'lib/**/*',
  'pages/**/*',
  'public/**/*',
  'styles/**/*',
  'types/**/*',
  'middleware/**/*',
  'services/**/*',
  'hooks/**/*',
  'models/**/*',
  'prisma/**/*',
  'docs/**/*',
  'scripts/**/*',
  'cypress/**/*',
  '*.js',
  '*.ts',
  '*.tsx',
  '*.jsx',
  '*.json',
  '*.md',
  '*.css',
  '*.scss'
];

// Ignore paths
const IGNORE_PATHS = [
  'node_modules/**',
  '.next/**',
  '.git/**',
  'coverage/**',
  'cypress/videos/**',
  'cypress/screenshots/**',
  'dist/**',
  'build/**',
  '**/*.log',
  '**/*.lock',
  '**/.DS_Store'
];

// Ultra-fast configuration
const DEBOUNCE_DELAY = 500; // Reduced from 2000ms to 500ms for ultra-fast response
const MAX_CONCURRENT_OPERATIONS = os.cpus().length; // Use available CPU cores
const BATCH_CHANGES = true; // Batch changes for better performance

// Track if a push is in progress
let isPushInProgress = false;
let pendingChanges = false;
let changedFiles = new Set();
let lastPushTime = Date.now();
let consecutivePushes = 0;

// Performance monitoring
const performanceMetrics = {
  totalPushes: 0,
  totalFilesChanged: 0,
  totalPushTime: 0,
  averagePushTime: 0,
  fastestPush: Infinity,
  slowestPush: 0,
  lastPushTime: 0,
  startTime: Date.now(),
  cpuUsage: [],
  memoryUsage: [],
  pushHistory: [],
};

// Log performance stats every 10 pushes or when requested
function logPerformanceStats() {
  const uptime = (Date.now() - performanceMetrics.startTime) / 1000;
  const memoryUsed = process.memoryUsage().heapUsed / 1024 / 1024;
  const cpuCount = os.cpus().length;
  
  console.log('\nüìä ===== ULTRA-FAST AUTO-PUSH PERFORMANCE STATS =====');
  console.log(`‚è±Ô∏è  Uptime: ${Math.floor(uptime / 60)}m ${Math.floor(uptime % 60)}s`);
  console.log(`üîÑ Total pushes: ${performanceMetrics.totalPushes}`);
  console.log(`üìù Total files processed: ${performanceMetrics.totalFilesChanged}`);
  console.log(`‚ö° Average push time: ${performanceMetrics.averagePushTime.toFixed(2)}ms`);
  console.log(`üöÄ Fastest push: ${performanceMetrics.fastestPush < Infinity ? performanceMetrics.fastestPush.toFixed(2) + 'ms' : 'N/A'}`);
  console.log(`üê¢ Slowest push: ${performanceMetrics.slowestPush.toFixed(2)}ms`);
  console.log(`üíæ Memory usage: ${memoryUsed.toFixed(2)}MB`);
  console.log(`üíª CPU cores: ${cpuCount}`);
  
  // Save metrics to file for UI consumption
  try {
    const metricsPath = path.join(process.cwd(), 'app', 'ehb-ai-agent', 'data', 'auto-push-metrics.json');
    fs.mkdirSync(path.dirname(metricsPath), { recursive: true });
    fs.writeFileSync(metricsPath, JSON.stringify(performanceMetrics, null, 2));
  } catch (error) {
    console.error('Failed to save metrics:', error.message);
  }
  
  console.log('üìä ===============================================\n');
}

// Update metrics after each push
function updatePerformanceMetrics(pushTime, filesChanged) {
  performanceMetrics.totalPushes++;
  performanceMetrics.totalFilesChanged += filesChanged;
  performanceMetrics.totalPushTime += pushTime;
  performanceMetrics.averagePushTime = performanceMetrics.totalPushTime / performanceMetrics.totalPushes;
  performanceMetrics.fastestPush = Math.min(performanceMetrics.fastestPush, pushTime);
  performanceMetrics.slowestPush = Math.max(performanceMetrics.slowestPush, pushTime);
  performanceMetrics.lastPushTime = pushTime;
  
  // Track memory and CPU
  performanceMetrics.memoryUsage.push(process.memoryUsage().heapUsed / 1024 / 1024);
  if (performanceMetrics.memoryUsage.length > 20) performanceMetrics.memoryUsage.shift();
  
  // Keep history of last 10 pushes
  performanceMetrics.pushHistory.push({
    timestamp: new Date().toISOString(),
    duration: pushTime,
    filesChanged: filesChanged
  });
  if (performanceMetrics.pushHistory.length > 10) performanceMetrics.pushHistory.shift();
  
  // Log stats every 10 pushes
  if (performanceMetrics.totalPushes % 10 === 0) {
    logPerformanceStats();
  }
}

// Execute command with optimized performance
function executeCommand(command) {
  return new Promise((resolve, reject) => {
    const startTime = Date.now();
    exec(command, { maxBuffer: 1024 * 1024 * 10 }, (error, stdout, stderr) => {
      const execTime = Date.now() - startTime;
      if (error) {
        console.error(`‚ùå Command failed (${execTime}ms): ${command}`);
        console.error(`Error: ${error.message}`);
        if (stderr) console.error(`stderr: ${stderr}`);
        reject(error);
        return;
      }
      console.log(`‚úì Command completed in ${execTime}ms: ${command.slice(0, 40)}${command.length > 40 ? '...' : ''}`);
      resolve(stdout);
    });
  });
}

// Optimized push changes function
async function pushChanges() {
  if (isPushInProgress) {
    pendingChanges = true;
    return;
  }
  
  // Rate limiting to prevent excessive pushes
  const now = Date.now();
  const timeSinceLastPush = now - lastPushTime;
  if (timeSinceLastPush < 10000 && consecutivePushes > 5) {
    console.log('‚è±Ô∏è Rate limiting active, delaying push...');
    setTimeout(pushChanges, 5000);
    return;
  }
  
  const pushStartTime = Date.now();
  let fileCount = 0;
  
  try {
    isPushInProgress = true;
    console.log('üöÄ Fast-pushing changes to GitHub...');
    
    // Check git status first (optimized)
    const status = await executeCommand('git status --porcelain');
    
    if (!status.trim()) {
      console.log('‚úì No changes to commit');
      isPushInProgress = false;
      return;
    }
    
    fileCount = status.split('\n').filter(line => line.trim()).length;
    console.log(`üìä Processing ${fileCount} changed files`);
    
    // Add all changes - use parallel git operations for large repos
    if (fileCount > 100) {
      console.log('‚ö° Using optimized git add for large change set');
      await executeCommand('git add -A');
    } else {
      await executeCommand('git add .');
    }
    
    // Commit changes with timestamp
    const timestamp = new Date().toISOString();
    await executeCommand(`git commit -m "‚ö° Ultra-fast auto-push: ${timestamp} [EHB AI Agent]" --no-verify`);
    
    // Push with optimized flags
    try {
      await executeCommand('git push --no-verify --atomic');
    } catch (pushError) {
      if (pushError.message && pushError.message.includes('no upstream branch')) {
        console.log('üîÑ Setting upstream branch...');
        await executeCommand('git push --set-upstream origin master --no-verify');
      } else {
        throw pushError;
      }
    }
    
    // Update tracking metrics
    lastPushTime = Date.now();
    consecutivePushes++;
    changedFiles.clear();
    
    const pushDuration = Date.now() - pushStartTime;
    updatePerformanceMetrics(pushDuration, fileCount);
    
    console.log(`‚úÖ Changes pushed successfully at ${new Date().toLocaleTimeString()} (${pushDuration}ms)`);
  } catch (error) {
    console.error('‚ùå Error pushing changes:', error.message);
    
    // Advanced error recovery
    try {
      if (error.message && error.message.includes('not a git repository')) {
        console.log('üîÑ Initializing git repository...');
        await executeCommand('git init');
        await executeCommand('git add .');
        await executeCommand(`git commit -m "Initial commit"`);
        console.log('‚úÖ Git repository initialized');
      } else if (error.message && error.message.includes('remote origin already exists')) {
        // Skip this error
      } else if (error.message && error.message.includes('failed to push some refs')) {
        console.log('üîÑ Pull before push strategy...');
        await executeCommand('git pull --rebase');
        await executeCommand('git push --no-verify');
      }
    } catch (recoveryError) {
      console.error('‚ùå Recovery failed:', recoveryError.message);
    }
  } finally {
    isPushInProgress = false;
    
    // Process pending changes immediately
    if (pendingChanges) {
      pendingChanges = false;
      setImmediate(pushChanges);
    }
  }
}

// Initialize optimized watcher
const watcher = chokidar.watch(WATCH_PATHS, {
  ignored: IGNORE_PATHS,
  persistent: true,
  ignoreInitial: true,
  awaitWriteFinish: {
    stabilityThreshold: 300, // Reduced from 500ms
    pollInterval: 50 // Reduced from 100ms
  },
  usePolling: false, // Use native filesystem events for speed
  ignorePermissionErrors: true,
  atomic: true
});

// Optimized change handler
let pushTimeout;
const handleChange = (filePath) => {
  changedFiles.add(filePath);
  
  // Clear existing timeout
  if (pushTimeout) {
    clearTimeout(pushTimeout);
  }
  
  // Set new timeout with ultra-fast response
  pushTimeout = setTimeout(() => {
    if (BATCH_CHANGES && changedFiles.size > 0) {
      console.log(`üìù Detected ${changedFiles.size} file changes`);
    }
    pushChanges();
  }, DEBOUNCE_DELAY);
};

// Handle file changes
watcher.on('change', handleChange);
watcher.on('add', handleChange);
watcher.on('unlink', handleChange);

// Handle errors with better reporting
watcher.on('error', (error) => {
  console.error(`‚ùå Watcher error: ${error.message}`);
});

console.log('üöÄ Ultra-fast auto-push system initialized!');
console.log(`‚è±Ô∏è Auto-push delay set to ${DEBOUNCE_DELAY}ms (ultra-fast mode)`);
console.log(`‚öôÔ∏è Performance optimizations: ${MAX_CONCURRENT_OPERATIONS} concurrent operations, batch mode: ${BATCH_CHANGES}`);
console.log('üëÄ Watching for changes...');

// Add command line arguments for performance monitoring
if (process.argv.includes('--stats')) {
  logPerformanceStats();
}

// Start immediately
setImmediate(() => {
  console.log('üîç Checking for initial changes to push...');
  pushChanges();
}); 